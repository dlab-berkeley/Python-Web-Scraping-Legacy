{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup: Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp')\n",
    "# Read the content of the server’s response\n",
    "src = req.text\n",
    "# Parse the response into an HTML tree\n",
    "soup = BeautifulSoup(src, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "\n",
    "Use Beautiful Soup to find all the `a` elements with class `mainmenu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select(\"a.mainmenu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2\n",
    "\n",
    "Extract all `href` attributes for each `mainmenu` URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[link['href'] for link in soup.select(\"a.mainmenu\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challege 3: Get `href` elements pointing to members' bills. \n",
    "\n",
    "The code above retrieves information on:  \n",
    "\n",
    "- the senator's name,\n",
    "- their district number,\n",
    "- and their party.\n",
    "\n",
    "We now want to retrieve the URL for each senator's list of bills. Each URL will follow a specific format. \n",
    "\n",
    "The format for the list of bills for a given senator is:\n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?GA=98&MemberID=[MEMBER_ID]&Primary=True`\n",
    "\n",
    "to get something like:\n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True`\n",
    "\n",
    "in which `MEMBER_ID=1911`. \n",
    "\n",
    "You should be able to see that, unfortunately, `MEMBER_ID` is not currently something pulled out in our scraping code.\n",
    "\n",
    "Your initial task is to modify the code above so that we also **retrieve the full URL which points to the corresponding page of primary-sponsored bills**, for each member, and return it along with their name, district, and party.\n",
    "\n",
    "Tips: \n",
    "\n",
    "* To do this, you will want to get the appropriate anchor element (`<a>`) in each legislator's row of the table. You can again use the `.select()` method on the `row` object in the loop to do this — similar to the command that finds all of the `td.detail` cells in the row. Remember that we only want the link to the legislator's bills, not the committees or the legislator's profile page.\n",
    "* The anchor elements' HTML will look like `<a href=\"/senate/Senator.asp/...\">Bills</a>`. The string in the `href` attribute contains the **relative** link we are after. You can access an attribute of a BeatifulSoup `Tag` object the same way you access a Python dictionary: `anchor['attributeName']`. See the <a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\">documentation</a> for more details.\n",
    "* There are a _lot_ of different ways to use BeautifulSoup to get things done. whatever you need to do to pull the `href` out is fine.\n",
    "\n",
    "The code has been partially filled out for you. Fill it in where it says `#YOUR CODE HERE`. Save the path into an object called `full_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp?GA=98')\n",
    "# Read the content of the server’s response\n",
    "src = req.text\n",
    "# Soup it\n",
    "soup = BeautifulSoup(src, \"lxml\")\n",
    "# Create empty list to store our data\n",
    "members = []\n",
    "\n",
    "# Returns every ‘tr tr tr’ css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "# Get rid of junk rows\n",
    "rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "# Loop through all rows\n",
    "for row in rows:\n",
    "    # Select only those 'td' tags with class 'detail'\n",
    "    detail_cells = row.select('td.detail') \n",
    "    # Keep only the text in each of those cells\n",
    "    row_data = [cell.text for cell in detail_cells]\n",
    "    # Collect information\n",
    "    name = row_data[0]\n",
    "    district = int(row_data[3])\n",
    "    party = row_data[4]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # Extract href\n",
    "    href = row.select('a')[1]['href']\n",
    "    # Create full path\n",
    "    full_path = \"http://www.ilga.gov/senate/\" + href + \"&Primary=True\"\n",
    "    \n",
    "    # Store in a tuple\n",
    "    senator = (name, district, party, full_path)\n",
    "    # Append to list\n",
    "    members.append(senator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Modularize Your Code\n",
    "\n",
    "Turn the code above into a function that accepts a URL, scrapes the URL for its senators, and returns a list of tuples containing information about each senator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_members(url):\n",
    "    # Make a GET request\n",
    "    req = requests.get(url)\n",
    "    # Read the content of the server’s response\n",
    "    src = req.text\n",
    "    # Soup it\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "    # Create empty list to store our data\n",
    "    members = []\n",
    "\n",
    "    # Returns every ‘tr tr tr’ css selector in the page\n",
    "    rows = soup.select('tr tr tr')\n",
    "    # Get rid of junk rows\n",
    "    rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "    # Loop through all rows\n",
    "    for row in rows:\n",
    "        # Select only those 'td' tags with class 'detail'\n",
    "        detail_cells = row.select('td.detail') \n",
    "        # Keep only the text in each of those cells\n",
    "        row_data = [cell.text for cell in detail_cells]\n",
    "        # Collect information\n",
    "        name = row_data[0]\n",
    "        district = int(row_data[3])\n",
    "        party = row_data[4]\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        # Extract href\n",
    "        href = row.select('a')[1]['href']\n",
    "        # Create full path\n",
    "        full_path = \"http://www.ilga.gov/senate/\" + href + \"&Primary=True\"\n",
    "\n",
    "        # Store in a tuple\n",
    "        senator = (name, district, party, full_path)\n",
    "        # Append to list\n",
    "        members.append(senator)\n",
    "    return(members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "url = 'http://www.ilga.gov/senate/default.asp?GA=98'\n",
    "senate_members = get_members(url)\n",
    "len(senate_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Writing a Scraper Function\n",
    "\n",
    "Finally, we want to scrape the webpages corresponding to bills sponsored by each bills.\n",
    "\n",
    "Write a function called `get_bills(url)` to parse a given bills URL. This will involve:\n",
    "\n",
    "  - requesting the URL using the <a href=\"http://docs.python-requests.org/en/latest/\">`requests`</a> library\n",
    "  - using the features of the `BeautifulSoup` library to find all of the `<td>` elements with the class `billlist`\n",
    "  - return a _list_ of tuples, each with:\n",
    "      - description (2nd column)\n",
    "      - chamber (S or H) (3rd column)\n",
    "      - the last action (4th column)\n",
    "      - the last action date (5th column)\n",
    "      \n",
    "This function has been partially completed. Fill in the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bills(url):\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src)\n",
    "    rows = soup.select('tr tr tr')\n",
    "    bills = []\n",
    "    # Iterate over rows\n",
    "    for row in rows:\n",
    "        # Grab all bill list cells\n",
    "        cells = row.select('td.billlist')\n",
    "        # Keep in mind the name of the senator is not a billlist class!\n",
    "        if len(cells) == 5:\n",
    "            row_text = [cell.text for cell in cells]\n",
    "            # Extract info from row text\n",
    "            bill_id = row_text[0]\n",
    "            description = row_text[1]\n",
    "            chamber = row_text[2]\n",
    "            last_action = row_text[3]\n",
    "            last_action_date = row_text[4]\n",
    "            # Consolidate bill info\n",
    "            bill = (bill_id, description, chamber, last_action, last_action_date)\n",
    "            bills.append(bill)\n",
    "    return bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = senate_members[0][3]\n",
    "get_bills(test_url)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6: Scrape All Bills\n",
    "\n",
    "Finally, create a dictionary `bills_dict` which maps a district number (the key) onto a list of bills (the value) coming from that district. You can do this by looping over all of the senate members in `members_dict` and calling `get_bills()` for each of their associated bill URLs.\n",
    "\n",
    "**NOTE:** please call the function `time.sleep(1)` for each iteration of the loop, so that we don't destroy the state's web site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "bills_dict = {}\n",
    "for member in senate_members[:5]:\n",
    "    bills_dict[member[1]] = get_bills(member[3])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bills_dict[52])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
